from __future__ import annotations

import logging
from typing import List

from sparsemap.core.config import get_settings
from sparsemap.domain.models import Graph
from sparsemap.services.llm_provider import LLMProvider
from sparsemap.services.providers import DeepSeekProvider, GeminiProvider


logger = logging.getLogger(__name__)


def _get_provider() -> LLMProvider:
    """
    Get LLM provider based on configuration

    Returns:
        LLMProvider: Configured provider instance

    Raises:
        ValueError: If provider is not supported
    """
    settings = get_settings()
    provider_name = settings.llm_provider.lower()

    if provider_name == "gemini":
        return GeminiProvider(
            api_key=settings.llm_api_key,
            model=settings.llm_model,
            temperature=settings.llm_temperature,
            max_tokens=settings.llm_max_tokens,
            max_retries=settings.llm_max_retries,
        )
    elif provider_name == "deepseek":
        return DeepSeekProvider(
            api_key=settings.llm_api_key,
            base_url=settings.llm_base_url,
            model=settings.llm_model,
            temperature=settings.llm_temperature,
            max_tokens=settings.llm_max_tokens,
            max_retries=settings.llm_max_retries,
        )
    else:
        raise ValueError(
            f"Unsupported LLM provider: {provider_name}. "
            f"Supported providers: gemini, deepseek"
        )


def build_prompt(contents: List[dict]) -> str:
    prompt = """你是一位资深的教学专家和知识架构师。请分析以下课程内容，提取逻辑骨架和知识依赖关系。

要求：
1. **识别主线逻辑**：课程的核心思想、步骤流程、关键主张（type: "main"）
2. **识别支线知识**：达成主线目标所需的技术工具、背景概念（type: "dependency"）
3. **最佳实践校验**：结合行业最佳实践，若文本遗漏关键步骤，请补充节点并标记 type 为 "suggested_best_practice"
4. **解释关系**：为每个依赖关系说明“为什么需要这个工具/概念”，节点提供 reason 字段

返回严格的 JSON 格式：
{
  "nodes": [
    {
      "id": "n1",
      "label": "节点名称",
      "type": "main" | "dependency" | "suggested_best_practice",
      "priority": "critical" | "optional",
      "reason": "节点出现的原因",
      "source": "url1" | "text1",
      "description": "节点描述"
    }
  ],
  "edges": [
    {
      "source": "n1",
      "target": "n2",
      "type": "depends_on" | "references" | "implements",
      "reason": "为什么需要这个依赖"
    }
  ],
  "summary": "整体课程逻辑的简要总结"
}

内容：
"""
    for content in contents:
        prompt += f"\n\n=== 来源 {content['source']} ===\n{content['text']}\n"
    return prompt


def analyze_contents(contents: List[dict]) -> Graph:
    """
    Analyze contents and generate knowledge graph using configured LLM provider

    Args:
        contents: List of content dictionaries with 'source' and 'text' keys

    Returns:
        Graph: Parsed knowledge graph

    Raises:
        ValueError: If generation or parsing fails
    """
    provider = _get_provider()
    prompt = build_prompt(contents)
    return provider.generate_graph(contents, prompt)
